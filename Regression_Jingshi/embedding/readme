Here is a brief introduction of each file under './embedding'.

tf_glove.py implements GloVe model on tensorflow, just run python tf_glove.py to training words embeddings.

First, it automatically calculates how many words there are in the vocabulary.
----Because I set some complex rule (see '../preprocess.py') to filter words and special characters, and set a minimal occurance number as 5, there are 2360 words in total.

Second, it build a calculation graph based on tensorflow and optimize it.
----Training parameters: 50 dimensions for word vectors, 500 epoches for training, context window size of 10

Finally, embed.png and embed.pkl are generated automatically.
----embed.png: tSNE is used here for visualizing 50 dimension vectors in 2 dimesions space, so the neighborhood relationship may not be the same as that in 50 dimenstions space!
----embed.pkl: restore a python dictionay object, with keys: 'word', 'vectors'.

remark: log.txt and training.png is recording manually.

To access the Word2Vec word vectors created using the Edinburgh corpus, download it from https://github.com/felipebravom/AffectiveTweets/releases/download/1.0.0/w2v.twitter.edinburgh10M.400d.csv.gz and save it in /embedding