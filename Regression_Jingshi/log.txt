Average Pearson correlation from 10 fold cross validation, using “bag of words” feature:
              SVM       XGBoost   MLP
     anger    0.4057    0.5024    0.4584
      fear    0.3903    0.4745    0.4480
       joy    0.5208    0.5281    0.4517
   sadness    0.3716    0.4230    0.4082

Average Pearson correlation from 10 fold cross validation, after improve regular_tweet, using “bag of words” feature:
              SVM       XGBoost   MLP
     anger    0.4074    0.5072    0.4805
      fear    0.3965    0.4573    0.4563
       joy    0.5290    0.5367    0.5667
   sadness    0.3776    0.4227    0.4029

Both the above table shows that SVM has the lowest Pearson correlation for all emotions. XGBoost performs better than MLP because bag of words feature is sparse, MLP is good at dense features while Gradient tree is good at sparse discrete variables. So for bag of words feature, it is more suitable to use XGBoost regressor.  

Average Pearson correlation from 10 fold cross validation, using GloVe embedding:
              SVM       XGBoost   MLP
     anger    0.1409    0.1923    0.2145
      fear    0.1361    0.2482    0.2810
       joy    0.1802    0.3571    0.4052
   sadness    0.1871    0.2421    0.3157

The above table shows that only use Glove embedding feature can not produce better results than bag of words feature. However, interestingly, MLP regressor performs better than the other two for all emotions. That is to say MLP regressor works better with GloVe vectors, because GloVe vectors are dense (i.e. every dimension has value) in nature. 

Average Pearson correlation from 10 fold cross validation, using both GloVe and bag of words by concatenation:
              SVM       XGBoost   MLP
     anger    0.2981    0.4404    0.4991
      fear    0.3298    0.4562    0.4720
       joy    0.4170    0.5295    0.5747
   sadness    0.3354    0.4071    0.4219

After concatenation of Glove and bag of words, the Pearson correlation improves by about 1% on average with MLP regressor.

